<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Armine's Page</title><meta name="description" content="A Blog Powered By Hexo"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/images/bitbug_favicon.ico"><link rel="stylesheet" href="/css/prontera.css"><link rel="search" type="application/opensearchdescription+xml" href="https://ar-mine.github.io/atom.xml" title="Armine's Page"><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="Armine's Page" type="application/atom+xml">
</head><body><header class="feature-header"><nav class="component-nav"><ul><div class="logo-container"><a href="/"><h2 class="title">Armine's Page</h2></a></div><a href="/" target="_self" class="li component-nav-item"><p class="selected">INDEX</p></a><a href="/archives" target="_self" class="li component-nav-item"><p>ARCHIVES</p></a><a href="/publication" target="_self" class="li component-nav-item"><p>PUBLICATION</p></a><a href="/project" target="_self" class="li component-nav-item"><p>PROJECT</p></a><ul class="shortcut-icons"><a href="https://github.com/ar-mine" target="_blank"><img src="/images/github.svg" class="icon"></a></ul></ul></nav></header><main class="container"><div id="body-container"><div id="post-list" class="left"><div class="home post-list"><div class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2022/09/23/about%20me/" class="post-title-link">About Me</a></h2><div class="post-info">Sep 23, 2022</div><div class="post-content"><p><strong>(This page is not adapted for mobile phones, so please try to browse it on the PC if you can.)</strong></p>
<p>I am a Research associate in <a target="_blank" rel="noopener" href="https://lvchen.wixsite.com/automan">AutomMan Lab</a> working with Asst Prof. Chen Lv at <a target="_blank" rel="noopener" href="https://www.ntu.edu.sg/">MAE, Nanyang Technology University (NTU), Singapore</a> now. I graduated from NTU and got my MSc. degree in Computer Control and Automation in Apr 2022 (Dissertation Supervisor: <a target="_blank" rel="noopener" href="https://personal.ntu.edu.sg/gqhu/index.html">Prof. GuoQiang Hu</a>). Before that, I received my B.Eng in Automation from <a target="_blank" rel="noopener" href="https://www.hfut.edu.cn/">Hefei University of Technology (HFUT), China</a> in Jun 2020. At undergraduate years, I tried to explore and conducted a preliminary look to some fields, such as <a href="/2018/01/25/teleoperated-car-based-on-EEG/" title="Teleoperated Car based on EEG control with Video Signal Stimulation">electroencephalography(EEG) interaction</a>, <a href="/2018/05/10/hexapod-robot/" title="Hexapod Robot(2018)">hexopod robot</a>, <a href="/2020/01/25/semantic-segmentation/" title="semantic-segmentation">computer vision</a> and <a href="https://ar-mine.github.io/publication/">reinforcement learning</a>. </p>
<p>Currently, I am responsible for manipulator part of the project in <a target="_blank" rel="noopener" href="https://www.ntu.edu.sg/continental-ntu">Continental-NTU Corporate Lab</a> whose goal is industrial application of cobot and aAGV. And the topic of master dissertation was researching Human-Robot-Interaction(HRI) applied on the manipulator, such as <a href="/2021/04/01/human-robot-interaction/" title="Human Robot Interaction(2021)">Human-to-Robot(H2R)</a> and <a href="/2022/01/27/human-robot-interaction2/" title="Human Robot Interaction(2022)">collision avoidance based on proximity sensors</a>. Now I am finding a Ph.D. position and want to research more about intelligence and its pratical application. If you are interested in me, please feel free to contact me.</p>
<p><strong>Research interests</strong>: computer vision, robotics, human robot interaction and reinforcement learning.</p></div><a href="/2022/09/23/about%20me/" class="read-more">READ MORE</a></article></div><div class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2022/01/27/human-robot-interaction2/" class="post-title-link">Human Robot Interaction(2022)</a></h2><div class="post-info">Jan 27, 2022</div><div class="post-content"><h1 id="Slow-Down-or-Stop-by-using-Proximity-Sensor"><a href="#Slow-Down-or-Stop-by-using-Proximity-Sensor" class="headerlink" title="Slow Down or Stop by using Proximity Sensor"></a>Slow Down or Stop by using Proximity Sensor</h1><br/>
<div style="padding:5px; float:left">
<img src="https://raw.githubusercontent.com/ar-mine/ar-mine.github.io/images/task1-real.gif" width=260px/>
</div>

<p>According to the distance to collision, the robot can do some reactions like slowing down and even stop if it is close enough. To avoid the influence of the ray shadowed by itself, I code with <a target="_blank" rel="noopener" href="https://github.com/flexible-collision-library/fcl">FCL</a> and implement the visualization of collision and self-collision check between robot body and sensors’ ray.</p>
<br/></div><a href="/2022/01/27/human-robot-interaction2/" class="read-more">READ MORE</a></article></div><div class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2021/04/01/human-robot-interaction/" class="post-title-link">Human Robot Interaction(2021)</a></h2><div class="post-info">Apr 1, 2021</div><div class="post-content"><h1 id="Human-Collision-Avoidance-based-on-Global-Skeleton-Detection"><a href="#Human-Collision-Avoidance-based-on-Global-Skeleton-Detection" class="headerlink" title="Human Collision Avoidance based on Global Skeleton Detection"></a>Human Collision Avoidance based on Global Skeleton Detection</h1><p>The quick glance(left) is a demo for exploring collision avoidance between humans and manipulators through global skeleton detection.(The camera is not shown in the animation, but you can see it in the picture(right) of workspace setup.)</p>
<p>We use <a target="_blank" rel="noopener" href="https://nuitrack.com/">Nuitrack</a> to detect skeleton keypoints of human and then model these points as spheres which are given collision volume so that <a target="_blank" rel="noopener" href="https://moveit.ros.org/">Moveit!</a> can plan a trajectory to avoid collision. If there is any potential collision appearing in the trajectory, the manipulator will stop first and replan a new path so that it can get around the obstacles.</p>
<div style="padding:5px; float:left">
<img src="https://raw.githubusercontent.com/ar-mine/ar-mine.github.io/images/human-collision-skeleton-experiment.gif" height=310px/>
</div>
<div style="padding:5px; float:right">
<img src="https://raw.githubusercontent.com/ar-mine/ar-mine.github.io/images/human-collision-skeleton-setup.jpg" height=310px/>
</div></div><a href="/2021/04/01/human-robot-interaction/" class="read-more">READ MORE</a></article></div><div class="post-list-item"><article class="post-block"><h2 class="post-title"><a href="/2018/05/10/hexapod-robot/" class="post-title-link">Hexapod Robot(2018)</a></h2><div class="post-info">May 10, 2018</div><div class="post-content"><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>The hexapod robot uses a master-slave control system with a high-performance MCU acting as the master who schedules the resources of each slave chip and takes on the computationally intensive work. The slave processor is mainly responsible for the control of the individual motion structures, thus reducing the load of the master.</p>
<p>The hexapod robot aims to search and rescue problems in complex and narrow environments. Therefore, we equipped it with Lidar and camera, and try to use ToF camera to improve the efficiency and accuracy of detection.</p>
<p>In the 1-year project, we implement the functions as below:</p>
<ol>
<li>The implementation of simple walking function with multiple processors, and capability of performing the corresponding basic movements according to the instructions of the remote control.</li>
<li>The implementation of obstacle avoidance with multi-modal perception(foot pressure, gyroscope, point cloud and RGB image).</li>
<li>The algorithm for walking over uneven surface.</div><a href="/2018/05/10/hexapod-robot/" class="read-more">READ MORE</a></article></div></div></div><div id="sidebar" class="left"><div id="about-panel"><div class="info"><div class="title">Armine</div><div class="url">https://ar-mine.github.io</div><div class="bio">RUNJIA TAN(谭润家 Chinese)</div></div><img src="/images/avatar.png" class="avatar"></div><div id="friend-links-panel"><div class="panel-title"><p>Contact me</p></div><a href="" target="_blank" class="link-item"><div class="link-container"><div class="site-name">Email</div><div class="site-desc">RUNJIA.TAN@ntu.edu.sg</div></div></a></div></div></div><div class="clear"></div></main><footer class="footer-container"><div class="paginator"></div><div class="copyright"><p>© 2022 <a href="https://ar-mine.github.io">Armine</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/AngryPowman/hexo-theme-prontera" target="_blank">hexo-theme-prontera</a>.</p></div></footer><script>(function(b,o,i,l,e,r){b.GoogleAnalyticsObject=l;b[l]||(b[l]=function(){(b[l].q=b[l].q||[]).push(arguments)});b[l].l=+new Date;e=o.createElement(i);r=o.getElementsByTagName(i)[0];e.src='//www.google-analytics.com/analytics.js';r.parentNode.insertBefore(e,r)}(window,document,'script','ga'));ga('create',"armine",'auto');ga('send','pageview');</script></body></html>